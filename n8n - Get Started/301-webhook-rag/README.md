# ğŸ’¬ 301 â€” Webhook + RAG (OpenRouter + Product Management Agent)

This folder contains the **Webhook + Retrieval-Augmented Generation (RAG)** workflow for **n8n**, powered by **OpenRouter**â€™s _deepseek-chat_ model.
It demonstrates how prompt wording and topic specificity change the AIâ€™s response â€” while adding a **RAG tool for Product Management insights**.

---

## âœ¨ Overview

This workflow expands the **201-basic** pattern by introducing **memory**, **OpenRouter free-tier LLM**, and a **RAG API tool** for contextual answers.
It creates a **Product Management AI Agent** that:

- ğŸ§  Uses **RAG** for **Product Management questions**
- ğŸ’¬ Uses the **LLM (deepseek-chat)** for **general or AWS-related questions**
- ğŸ™… Politely declines **out-of-scope or non-relevant questions**
- ğŸ§ Keeps short, simple replies (2â€“3 sentences), emphasizing clarity and prompt impact

---

## ğŸ”„ How It Works

```mermaid
graph LR
  A["ğŸŒ Webhook (POST)"] --> B["ğŸ§  AI Agent"]
  B --> C["ğŸ¤– OpenRouter Chat Model (deepseek-chat)"]
  B --> D["ğŸ› ï¸ RAG Tool (Product Management API)"]
  B <--> E["ğŸ—‚ï¸ Memory (sessionKey = username)"]
  B --> F["â†©ï¸ Respond to Webhook"]
```

1. **Webhook** receives JSON (`query`, `username`).
2. **AI Agent** decides how to respond:

   - If the topic involves **Product Management** â†’ call the **RAG Tool**.
   - Otherwise â†’ use the **deepseek-chat** model directly.
   - For vague questions â†’ respond generally and guide users to be more specific.

3. **Memory Buffer (Window)** stores short-term conversation context by username.
4. **Response Node** returns the generated reply to the client.

---

## ğŸ›‚ Inputs (JSON Body)

| Field      | Type   | Required       | Description                           |
| ---------- | ------ | -------------- | ------------------------------------- |
| `query`    | string | âœ…             | Userâ€™s input message                  |
| `username` | string | ğŸŸ¢ Recommended | Session key for conversational memory |

**Example**

```json
{
  "query": "What are best practices for Product Managers when prioritizing features?",
  "username": "demo-user-1"
}
```

---

## ğŸ“¤ Output

- **HTTP 200 OK** with a short AI reply.
- Reply style examples:

  - â€œ(Answer from Product Management knowledge base)â€ â€” via RAG Tool
  - â€œ(General or AWS-based answer)â€ â€” via model
  - â€œ(Out-of-scope polite refusal)â€ â€” for unrelated queries

---

## âš™ï¸ Setup

1. **Import** `301-webhook-rag.json` into your **n8n Cloud** workspace.
2. **Credentials â†’ Configure:**

   - ğŸ”‘ **OpenRouter API** (create a free account at [openrouter.ai](https://openrouter.ai))
   - ğŸ”‘ Optional: API key for the **Traversaal Product Docs API** (used by the RAG Tool)

3. **In the â€œRAG Toolâ€ node**, replace:

   ```bash
   Authorization: your_traversaal_api_auth_brearer_token_here
   ```

   with your actual bearer token.

4. **Activate** the workflow and copy the **Production Webhook URL** (from the Webhook node).
5. Optionally adjust the `systemMessage` inside the AI Agent node to modify tone or domain focus.

---

## ğŸ§ª Try It

### Option A â€” Google Colab (Recommended)

1. Open the instructorâ€™s Colab notebook:
   **[301 Webhook + RAG â€” Client (Colab)](https://colab.research.google.com/drive/1o66IjJDEQZ404gs5MNiItm2WqxcU2bzx?usp=sharing)**
2. Click **File â†’ Save a copy in Drive**.
3. Replace `WEBHOOK_URL` with your **Production Webhook URL** from n8n.
4. Run all cells and test:

   - ğŸ§  â€œWhat are best practices for Product Managers?â€
   - â˜ï¸ â€œTell me about AWS S3 buckets.â€
   - ğŸ™ï¸ â€œWhat is the capital of France?â€

> ğŸ’¡ Use the same `username` to maintain context; new names start fresh sessions.

---

### Option B â€” cURL

```bash
WEBHOOK_URL="https://<your-n8n>/webhook/<id>"   # Use Production URL
curl -X POST "$WEBHOOK_URL" \
  -H "Content-Type: application/json" \
  -d '{"query":"List key principles of Product Management","username":"demo-user-1"}'
```

### Option C â€” Postman

1. Create a **POST** request â†’ `Production Webhook URL`
2. Body â†’ Raw â†’ JSON:

   ```json
   {
     "query": "How can I improve sprint planning as a Product Manager?",
     "username": "demo-user-1"
   }
   ```

3. Click **Send** â†’ view AI reply.

---

## ğŸ§  What to Notice (Teaching Points)

- Demonstrates **how prompt wording changes the modelâ€™s specificity**.
- Shows **AI tool routing** (LLM vs RAG) within a single workflow.
- Highlights the benefit of **contextual memory** via `sessionKey`.
- Provides a **budget-friendly OpenRouter setup** (deepseek-chat is free tier).
- Encourages experimentation with tone and system instructions.

---

## ğŸ“š References

- ğŸ“– [Traversaal Product Management Docs API](https://pro-documents.traversaal-api.com/)
- ğŸ“– [OpenRouter â€” deepseek-chat model](https://openrouter.ai/models/deepseek/deepseek-chat)
- ğŸ“– [n8n â€” AI Agent node](https://docs.n8n.io/ai/agents/)
- ğŸ“– [n8n â€” HTTP Request Tool](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/)
- ğŸ“– [n8n â€” Memory Buffer Window](https://docs.n8n.io/ai/memory/)

---

## ğŸ“ Learn More

Want to go deeper into AI workflows and agents?

- [**AI Bootcamp: Generative AI Beyond the Hype**](https://maven.com/boring-bot/ml-system-design) â€” for leaders & builders.
- [**Agent Engineering Bootcamp**](https://maven.com/boring-bot/advanced-llm) â€” for developers scaling real AI systems.

> ğŸª„ Learn how to chain OpenRouter, RAG, and custom APIs in your own workflows â€” the same pattern used here.
