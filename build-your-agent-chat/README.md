Hereâ€™s a **friendly, simple README** in the same â€œloveableâ€ style and tone â€” ready for your repo ðŸ‘‡

---

# ðŸ’¬ Build a Perplexity-Style AI Chat App

A beautiful, minimal chat interface that connects directly to your **n8n workflow**.
Every message you send goes straight to your AI workflow â€” and comes back as an instant, smart reply ðŸ¤–âœ¨

---

## ðŸš€ What Youâ€™ll Build

- ðŸ  **Setup Page:** User enters their name
- ðŸ’¬ **Chat Page:** Type messages â†’ get AI responses from n8n
- ðŸ’¾ **Local History:** Messages stay even after refresh
- ðŸ§¹ **Clear Chat:** Start fresh anytime
- â³ **â€œThinkingâ€¦â€ Loader:** See when AI is working
- âš¡ **Error Handling:** Friendly toasts if something goes wrong

---

## ðŸ”— Connect Your n8n Workflow

1. **Activate** your n8n workflow
2. Copy the **Production Webhook URL** (âš ï¸ _not the test one!_)
3. Open the project â†’ go to `src/config.ts`
4. Replace the placeholder:

   ```ts
   export const WEBHOOK_URL = ">>YOUR_PRODUCTION_WEBHOOK_URL<<";
   ```

5. Run the app â€” thatâ€™s it ðŸŽ‰

---

## ðŸ“¦ Data Flow

### ðŸ“¨ Request (sent to n8n)

```json
{
  "query": "user's question",
  "username": "username"
}
```

### ðŸ“¬ Response (from n8n)

n8n can reply with either:

```json
{
  "output": "AI assistant's answer"
}
```

or

```json
[
  {
    "output": "AI assistant's answer"
  }
]
```

ðŸ’¡ Make sure your app handles both â€” and ignores empty or invalid replies gracefully.

---

## â¤ï¸ Built-in Goodness

- Smart response parsing ðŸ§ 
- Local storage for chats ðŸ’¾
- Auto-refresh themes ðŸŽ¨
- No extra setup â€” just plug in your webhook and go ðŸš€

---

### ðŸ§  Tips

If you see â€œthinkingâ€¦â€ for too long, check:

- Your n8n workflow is active âœ…
- Youâ€™re using the **Production Webhook URL** ðŸŒ
- The workflow actually returns `output` in its JSON ðŸ§¾

---

Would you like me to add a short **PR description** (for your `frontend/build-your-agent-chat` branch) to go with this README â€” matching the repoâ€™s tone and emoji style?
